{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea816a14",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409e6f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# import pandas\n",
    "import json\n",
    "\n",
    "# from sklearn.externals import joblib\n",
    "import pickle\n",
    "from importlib.resources import path\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.utils\n",
    "from pandas import Int64Index, MultiIndex\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80722998",
   "metadata": {},
   "source": [
    "#### Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec1dd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\fincrime-federated\n",
      "   Timestamp                                  UETR    Sender  Receiver  \\\n",
      "0 2022-01-01  f474fdb3-4675-4fff-ab7e-3469f82bd6a7  DPSUFRPP  ABVVUS6S   \n",
      "1 2022-01-01  c9158def-dab1-4bfb-a31f-7f51c6679d60  BRRGPTPL  CBLHESMM   \n",
      "2 2022-01-01  d371ba0a-823f-4243-98ba-94ff18523420  BRRGPTPL  CBLHESMM   \n",
      "3 2022-01-01  5a53a257-4dc9-4800-abb2-4cd1d55c8345  DPSUFRPP  ABVVUS6S   \n",
      "4 2022-01-01  f27867ac-35e2-46af-8248-0a2d0d9bf00d  DPSUFRPP  ABVVUS6S   \n",
      "\n",
      "  TransactionReference         OrderingAccount                  OrderingName  \\\n",
      "0    PETX22-FXIDA-7054  FR90714755422956984353         PHACELIA HETEROPHYLLA   \n",
      "1    PETX22-NO-FX-1736   PT8895792452733129969     GONOLOBUS STEPHANOTRICHUS   \n",
      "2    PETX22-NO-FX-1687  PT92895792452733126420  LECHEA INTERMEDIA-INTERMEDIA   \n",
      "3     DPSU22-FXIYA-517      358727697099645998                   SCLERANTHUS   \n",
      "4   PETX22-FXIDA-11878  FR71714755422956985471          SELAGINELLA ASPRELLA   \n",
      "\n",
      "           OrderingStreet       OrderingCountryCityZip  \\\n",
      "0            3| RUE HAMON      FR/42859 SAINTE AURÉLIE   \n",
      "1       AV RITA ALVES| 60       PT/5863-752 CANTANHEDE   \n",
      "2       PRAÇA VALENTE| 85         PT/1100-087 BARCELOS   \n",
      "3  341 4 CHOME 4 BAN 2 GO  JP/FUKUOKA PREFECTURE|ŌKAWA   \n",
      "4   28| BOULEVARD LÉVÊQUE              FR/36357 TURPIN   \n",
      "\n",
      "       BeneficiaryAccount  ...                    Name_order  \\\n",
      "0      611024064274704358  ...         PHACELIA HETEROPHYLLA   \n",
      "1  ES61897100852916932423  ...     GONOLOBUS STEPHANOTRICHUS   \n",
      "2  ES31897100852916935097  ...  LECHEA INTERMEDIA-INTERMEDIA   \n",
      "3      611024064274698543  ...                   SCLERANTHUS   \n",
      "4      611024064274707099  ...          SELAGINELLA ASPRELLA   \n",
      "\n",
      "             Street_order         CountryCityZip_order  Flags_order  Bank_ben  \\\n",
      "0            3, RUE HAMON      FR/42859 SAINTE AURÉLIE          0.0  ABVVUS6S   \n",
      "1       AV RITA ALVES, 60       PT/5863-752 CANTANHEDE          0.0  CBLHESMM   \n",
      "2       PRAÇA VALENTE, 85         PT/1100-087 BARCELOS          0.0  CBLHESMM   \n",
      "3  341 4 CHOME 4 BAN 2 GO  JP/FUKUOKA PREFECTURE,ŌKAWA          0.0  ABVVUS6S   \n",
      "4   28, BOULEVARD LÉVÊQUE              FR/36357 TURPIN          0.0  ABVVUS6S   \n",
      "\n",
      "              Account_ben                      Name_ben  \\\n",
      "0      611024064274704358          PAPAVER CALIFORNICUM   \n",
      "1  ES61897100852916932423  MINUARTIA NUTTALLII-GREGARIA   \n",
      "2  ES31897100852916935097         ASTRAGALUS MAGDALENAE   \n",
      "3      611024064274698543         SYNGONIUM PODOPHYLLUM   \n",
      "4      611024064274707099           GALACTIA PARVIFOLIA   \n",
      "\n",
      "                              Street_ben      CountryCityZip_ben Flags_ben  \n",
      "0                     2584 CHARLES PLACE  US/ROJASLAND, DC 58442       0.0  \n",
      "1  ACCESO DE CARMINA ARAGÓN 83 PUERTA 4          ES/ÁVILA, 02281       0.0  \n",
      "2               PASADIZO ANÍBAL LUJÁN 57       ES/SEGOVIA, 40727       0.0  \n",
      "3              7864 MORRIS MEWS APT. 464         US/DPO AE 78549       0.0  \n",
      "4                     363 ROBERT GARDENS  US/NEW KAREN, MS 49461       0.0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "dirname = os.path.dirname('D:/fincrime-federated/')\n",
    "os.chdir(dirname)\n",
    "print(os.getcwd())\n",
    "\n",
    "import submission_src.fincrime.solution_centralized as funcs\n",
    "importlib.reload(funcs) \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model_dir = 'D:/fincrime-federated/model/fincrime'\n",
    "preds_format_path = 'D:/fincrime-federated/prediction/fincrime/prediction_format'\n",
    "preds_dest_path = 'D:/fincrime-federated/prediction/fincrime/prediction'\n",
    "\n",
    "\n",
    "## train on data\n",
    "datapathjsonString = 'data/fincrime/centralized/train/data.json'\n",
    "swift_data_path = funcs.json_to_dict(datapathjsonString)['swift_data_path']\n",
    "bank_data_path = funcs.json_to_dict(datapathjsonString)['bank_data_path']\n",
    "\n",
    "# trainset = funcs.fit(swift_data_path = swift_data_path,\n",
    "#                     bank_data_path = bank_data_path,\n",
    "#                     model_dir = model_dir,\n",
    "#                     preds_format_path = preds_format_path,\n",
    "#                     preds_dest_path = preds_dest_path,\n",
    "#                     m = 'xgboost')\n",
    "def json_to_dict(datapathjsonString):\n",
    "    datapathJson = open(datapathjsonString)\n",
    "    datapathDict = json.load(datapathJson)\n",
    "    return datapathDict\n",
    "\n",
    "\n",
    "def load_data(swift_data_path, bank_data_path):\n",
    "    swift_data = pd.read_csv(swift_data_path, index_col=\"MessageId\")\n",
    "    swift_data[\"Timestamp\"] = swift_data[\"Timestamp\"].astype(\"datetime64[ns]\")\n",
    "    bank_data = pd.read_csv(bank_data_path)\n",
    "    return swift_data, bank_data\n",
    "\n",
    "train_data, bank_data = load_data(\n",
    "    swift_data_path=swift_data_path, bank_data_path=bank_data_path\n",
    ")\n",
    "\n",
    "# Merging with bank details\n",
    "train_data = pd.merge(\n",
    "    train_data,\n",
    "    bank_data,\n",
    "    left_on=\"OrderingAccount\",\n",
    "    right_on=\"Account\",\n",
    "    how=\"left\",\n",
    ")\n",
    "train_data = pd.merge(\n",
    "    train_data,\n",
    "    bank_data,\n",
    "    left_on=\"BeneficiaryAccount\",\n",
    "    right_on=\"Account\",\n",
    "    how=\"left\",\n",
    "    suffixes=[\"_order\", \"_ben\"],\n",
    ")\n",
    "trainset = train_data\n",
    "print(trainset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abdb0d1",
   "metadata": {},
   "source": [
    "#### Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4cbf92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Timestamp                                  UETR    Sender  \\\n",
      "0 2022-01-28 22:15:00  43a12cd8-e14b-4737-a5a4-39b124468509  ZOUOGB22   \n",
      "1 2022-01-29 05:34:00  ce04b39a-8162-43d6-ab82-f36705d1326a  WVOLDEMM   \n",
      "2 2022-01-29 07:31:00  8f7fe9e4-b8cf-46fd-9412-e6c6bc6891db  ABVVUS6S   \n",
      "3 2022-01-30 23:07:00  037045bd-ea1b-4b1e-bc86-9c3c287353be  CBLHESMM   \n",
      "4 2022-01-29 09:24:00  6d17c9e0-42f5-4081-a3f7-49b2a85cc7c8  ZOUOGB22   \n",
      "\n",
      "   Receiver TransactionReference         OrderingAccount  \\\n",
      "0  FJKNESMM   PETX22-FXIDA-11158  GB43679059808029769468   \n",
      "1  MBYOTRIS     PETX22-NO-FX-996  DE50020224692198579962   \n",
      "2  WVOLDEMM     PETX22-FXIGA-828             6.11024E+17   \n",
      "3  FJKNESMM    PETX22-NO-FX-1595  ES11897100852916939240   \n",
      "4  WMVZGB2L    PETX22-FXIDA-9106  GB69679059808029738445   \n",
      "\n",
      "                     OrderingName                         OrderingStreet  \\\n",
      "0                 SABAL CAUSIARUM            14 CLARE ISLAND JOSHUAMOUTH   \n",
      "1                  IRIS FERNALDII                  BETINA-ULLRICH-RING 0   \n",
      "2  RANUNCULUS FLAMMULA-FILIFORMIS                             USS WALKER   \n",
      "3           LIPOCARPHA DRUMMONDII         GLORIETA FABRICIO BENAVENTE 84   \n",
      "4                RIBES MARSHALLII  STUDIO 41 DAVIDSON PRAIRIE LAKE ROSIE   \n",
      "\n",
      "       OrderingCountryCityZip      BeneficiaryAccount  ...  \\\n",
      "0                  GB/E11 0ET  ES23877514433102593735  ...   \n",
      "1            DE/15085 ROSTOCK  TR95377507394253378041  ...   \n",
      "2  US/PORT DAWNBERG| RI 39406  FR92714755422956992562  ...   \n",
      "3           ES/SEGOVIA| 24876  ES78877514433102593812  ...   \n",
      "4                  GB/E0H 5ZX             1.99377E+17  ...   \n",
      "\n",
      "              Name_order                           Street_order  \\\n",
      "0        SABAL CAUSIARUM            14 CLARE ISLAND JOSHUAMOUTH   \n",
      "1         IRIS FERNALDII                  BETINA-ULLRICH-RING 0   \n",
      "2                    NaN                                    NaN   \n",
      "3  LIPOCARPHA DRUMMONDII         GLORIETA FABRICIO BENAVENTE 84   \n",
      "4       RIBES MARSHALLII  STUDIO 41 DAVIDSON PRAIRIE LAKE ROSIE   \n",
      "\n",
      "  CountryCityZip_order  Flags_order  Bank_ben             Account_ben  \\\n",
      "0           GB/E11 0ET          0.0  FJKNESMM  ES23877514433102593735   \n",
      "1     DE/15085 ROSTOCK          0.0  MBYOTRIS  TR95377507394253378041   \n",
      "2                  NaN          NaN  DPSUFRPP  FR92714755422956992562   \n",
      "3    ES/SEGOVIA, 24876          0.0  FJKNESMM  ES78877514433102593812   \n",
      "4           GB/E0H 5ZX          0.0       NaN                     NaN   \n",
      "\n",
      "                     Name_ben                        Street_ben  \\\n",
      "0                   PARNASSIA  CALLE DE FEBE MENDEZ 2 PUERTA 2    \n",
      "1                   SYNGONIUM                21295 ASLAN STREET   \n",
      "2  LATHYRUS VESTITUS-VESTITUS          887, BOULEVARD DE IMBERT   \n",
      "3    ALICIELLA PENSTEMONOIDES         ALAMEDA DE MARCOS RUIZ 47   \n",
      "4                         NaN                               NaN   \n",
      "\n",
      "        CountryCityZip_ben Flags_ben  \n",
      "0         ES/GIRONA, 05585       0.0  \n",
      "1  TR/CIHANHAVEN, IA 14541       0.0  \n",
      "2     FR/39058 SAINTE LÉON       0.0  \n",
      "3          ES/SORIA, 50602       0.0  \n",
      "4                      NaN       NaN  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Total time taken  241.42479848861694  seconds\n"
     ]
    }
   ],
   "source": [
    "# predict on test data\n",
    "import submission_src.fincrime.solution_centralized as funcs\n",
    "importlib.reload(funcs) \n",
    "\n",
    "datapathjsonString = 'data/fincrime/centralized/test/data.json'\n",
    "swift_data_path = funcs.json_to_dict(datapathjsonString)['swift_data_path']\n",
    "bank_data_path = funcs.json_to_dict(datapathjsonString)['bank_data_path']\n",
    "\n",
    "\n",
    "test_data, bank_data = load_data(\n",
    "    swift_data_path=swift_data_path, bank_data_path=bank_data_path\n",
    ")\n",
    "\n",
    "# Merging with bank details\n",
    "test_data = pd.merge(\n",
    "    test_data,\n",
    "    bank_data,\n",
    "    left_on=\"OrderingAccount\",\n",
    "    right_on=\"Account\",\n",
    "    how=\"left\",\n",
    ")\n",
    "test_data = pd.merge(\n",
    "    test_data,\n",
    "    bank_data,\n",
    "    left_on=\"BeneficiaryAccount\",\n",
    "    right_on=\"Account\",\n",
    "    how=\"left\",\n",
    "    suffixes=[\"_order\", \"_ben\"],\n",
    ")\n",
    "\n",
    "testset = test_data\n",
    "print(testset.head())\n",
    "print(\"Total time taken \", (time.time() - start_time),\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5576db",
   "metadata": {},
   "source": [
    "### Dropping Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777e901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset.dropna(axis=0,how='any',inplace=True)\n",
    "# print(\"trainset shape is:\"trainset.shape)\n",
    "# testset.dropna(axis=0,how='any',inplace=True)\n",
    "# print(\"testset shape is:\"testset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1561a65",
   "metadata": {},
   "source": [
    "### Normalization / Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29948744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stats(train_dataset):\n",
    "#     train_stats = train_dataset.describe()\n",
    "#     train_stats = train_stats.transpose()\n",
    "#     return train_stats\n",
    "\n",
    "# def norm(x):\n",
    "#     train_stats=stats(x)\n",
    "#     return (x - train_stats['mean']) / train_stats['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f66d4d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# scaler = RobustScaler(quantile_range=(25, 75))\n",
    "\n",
    "def norm(x):\n",
    "    scaler.fit(x)\n",
    "    return scaler.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35aa747",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd2db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_by_features(\n",
    "    df,\n",
    "    level_1,\n",
    "    level_2,\n",
    "    model_dir,\n",
    "    save_as_object=False,\n",
    "    map_from_train_set=False,\n",
    ") -> None:\n",
    "\n",
    "    if map_from_train_set == True:\n",
    "\n",
    "        level_1_level_2_frequency = pickle.load(\n",
    "            open(\n",
    "                model_dir\n",
    "                + \"/\"\n",
    "                + str(level_1 + \"_\" + level_2 + \"_frequency\")\n",
    "                + \".sav\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        _level_1 = df.loc[:, level_1].unique()\n",
    "        _level_2 = df.loc[:, level_2].unique()\n",
    "        df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
    "            :, level_2\n",
    "        ].astype(str)\n",
    "        df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
    "            :, str(level_1 + \"_\" + level_2)\n",
    "        ].map(level_1_level_2_frequency)\n",
    "    else:\n",
    "        _level_1 = df.loc[:, level_1].unique()\n",
    "        _level_2 = df.loc[:, level_2].unique()\n",
    "        df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
    "            :, level_2\n",
    "        ].astype(str)\n",
    "        level_1_level_2_frequency = {}\n",
    "        for s in _level_1:\n",
    "            level_1_rows = df[df[level_1] == s]\n",
    "            for h in _level_2:\n",
    "                level_1_level_2_frequency[s + str(h)] = len(\n",
    "                    level_1_rows[level_1_rows.loc[:, level_2] == h]\n",
    "                )\n",
    "\n",
    "        df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
    "            :, str(level_1 + \"_\" + level_2)\n",
    "        ].map(level_1_level_2_frequency)\n",
    "\n",
    "        if save_as_object == True:\n",
    "            pickle.dump(\n",
    "                level_1_level_2_frequency,\n",
    "                open(\n",
    "                    model_dir\n",
    "                    + \"/\"\n",
    "                    + str(level_1 + \"_\" + level_2 + \"_frequency\")\n",
    "                    + \".sav\",\n",
    "                    \"wb\",\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cbc173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep1(train_data):\n",
    "    # Feature engineering\n",
    "#     train_data = train_data.dropna(axis=0)\n",
    "    \n",
    "    train_data = create_features(\n",
    "        df=train_data, model_dir=model_dir, map_from_train_set=False\n",
    "    )\n",
    "\n",
    "    # Keep below columns for training and testing\n",
    "    cols_to_keep = [\n",
    "        \"SettlementAmount\",\n",
    "        \"InstructedAmount\",\n",
    "        \"Label\",\n",
    "        \"hour\",\n",
    "        \"Flags_ben\",\n",
    "        \"MissingBenAccount\",\n",
    "        \"MissingOrdAccount\",\n",
    "        \"Sender_hour_frequency\",\n",
    "        # 'sender_currency_amount_average',\n",
    "        \"Sender_Receiver_frequency\",\n",
    "        \"Sender_InstructedCurrency_frequency\",\n",
    "        \"seq\",\n",
    "        # 'receiver_transactions',\n",
    "        \"Receiver_SettlementCurrency_frequency\",\n",
    "        \"Receiver_hour_frequency\",\n",
    "        \"DifferentOrderNum\",\n",
    "        \"DifferentBenNum\",\n",
    "        \"DifferentOrderName\",\n",
    "        \"DifferentBenName\",\n",
    "        \"DifferentOrderStreet\",\n",
    "        \"DifferentBenStreet\",\n",
    "        \"DifferentOrderZip\",\n",
    "        \"DifferentBenZip\",\n",
    "    ]\n",
    "\n",
    "    train_data_2 = train_data[cols_to_keep]\n",
    "    return train_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56b66cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep2(train_data):\n",
    "    # Feature engineering\n",
    "#     train_data = train_data.dropna(axis=0)\n",
    "    train_data = create_features(\n",
    "        df=train_data, model_dir=model_dir, map_from_train_set=True\n",
    "    )\n",
    "\n",
    "    # Keep below columns for training and testing\n",
    "    cols_to_keep = [\n",
    "        \"SettlementAmount\",\n",
    "        \"InstructedAmount\",\n",
    "        \"Label\",\n",
    "        \"hour\",\n",
    "        \"Flags_ben\",\n",
    "        \"MissingBenAccount\",\n",
    "        \"MissingOrdAccount\",\n",
    "        \"Sender_hour_frequency\",\n",
    "        # 'sender_currency_amount_average',\n",
    "        \"Sender_Receiver_frequency\",\n",
    "        \"Sender_InstructedCurrency_frequency\",\n",
    "        \"seq\",\n",
    "        # 'receiver_transactions',\n",
    "        \"Receiver_SettlementCurrency_frequency\",\n",
    "        \"Receiver_hour_frequency\",\n",
    "        \"DifferentOrderNum\",\n",
    "        \"DifferentBenNum\",\n",
    "        \"DifferentOrderName\",\n",
    "        \"DifferentBenName\",\n",
    "        \"DifferentOrderStreet\",\n",
    "        \"DifferentBenStreet\",\n",
    "        \"DifferentOrderZip\",\n",
    "        \"DifferentBenZip\",\n",
    "    ]\n",
    "\n",
    "    train_data_2 = train_data[cols_to_keep]\n",
    "    return train_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e26e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, model_dir, map_from_train_set=False):\n",
    "\n",
    "    ## Feature Engineering\n",
    "\n",
    "    # Hour column\n",
    "    df[\"hour\"] = df[\"Timestamp\"].dt.hour\n",
    "\n",
    "    # Hour frequency for each sender\n",
    "    freq_by_features(\n",
    "        df=df,\n",
    "        level_1=\"Sender\",\n",
    "        level_2=\"hour\",\n",
    "        model_dir=model_dir,\n",
    "        save_as_object=True,\n",
    "        map_from_train_set=map_from_train_set,\n",
    "    )\n",
    "    # Hour frequency for each receiver\n",
    "    freq_by_features(\n",
    "        df=df,\n",
    "        level_1=\"Receiver\",\n",
    "        level_2=\"hour\",\n",
    "        model_dir=model_dir,\n",
    "        save_as_object=True,\n",
    "        map_from_train_set=map_from_train_set,\n",
    "    )\n",
    "    # Sender-Currency Frequency\n",
    "    freq_by_features(\n",
    "        df=df,\n",
    "        level_1=\"Sender\",\n",
    "        level_2=\"InstructedCurrency\",\n",
    "        model_dir=model_dir,\n",
    "        save_as_object=True,\n",
    "        map_from_train_set=map_from_train_set,\n",
    "    )\n",
    "    # Receiver-SettledCurrency Frequency\n",
    "    freq_by_features(\n",
    "        df=df,\n",
    "        level_1=\"Receiver\",\n",
    "        level_2=\"SettlementCurrency\",\n",
    "        model_dir=model_dir,\n",
    "        save_as_object=True,\n",
    "        map_from_train_set=map_from_train_set,\n",
    "    )\n",
    "    # Sender-Receiver Frequency\n",
    "    freq_by_features(\n",
    "        df=df,\n",
    "        level_1=\"Sender\",\n",
    "        level_2=\"Receiver\",\n",
    "        model_dir=model_dir,\n",
    "        save_as_object=True,\n",
    "        map_from_train_set=map_from_train_set,\n",
    "    )\n",
    "\n",
    "    # # Average Amount per Sender-Currency - not working\n",
    "    # Sender_ICurrency_mean = mean_by_features(df = df, level_1=\"Sender\" , level_2=\"InstructedCurrency\")\n",
    "    # df.loc[:,\"Sender_ICurrency_mean\"] = \\\n",
    "    #     df.loc[:,\"Sender_InstructedCurrency\"].map(Sender_ICurrency_mean)\n",
    "\n",
    "    # Numbering the transactions within a account order - ben - date combination\n",
    "    df = df.sort_values(\n",
    "        by=[\n",
    "            \"SettlementDate\",\n",
    "            \"Sender\",\n",
    "            \"Receiver\",\n",
    "            \"Account_order\",\n",
    "            \"Account_ben\",\n",
    "            \"Timestamp\",\n",
    "        ],\n",
    "        ascending=True,\n",
    "    )\n",
    "    df[\"seq\"] = (\n",
    "        df.groupby(\n",
    "            [\n",
    "                \"SettlementDate\",\n",
    "                \"Sender\",\n",
    "                \"Receiver\",\n",
    "                \"Account_order\",\n",
    "                \"Account_ben\",\n",
    "            ]\n",
    "        ).cumcount()\n",
    "        + 1\n",
    "    )\n",
    "    df[\"seq\"] = df[\"seq\"].replace(np.NAN, 1)\n",
    "\n",
    "    # Flag columns for transactions with missing bank details\n",
    "    df[[\"MissingBenAccount\"]] = 0\n",
    "    df.loc[df[\"Flags_ben\"].isnull(), \"MissingBenAccount\"] = 1\n",
    "    df[[\"MissingOrdAccount\"]] = 0\n",
    "    df.loc[df[\"Flags_order\"].isnull(), \"MissingOrdAccount\"] = 1\n",
    "\n",
    "    # Different sender account number from bank details\n",
    "    df[\"DifferentOrderNum\"] = np.where(\n",
    "        df[\"Account_order\"] == df[\"OrderingAccount\"], 0, 1\n",
    "    )\n",
    "    # Different receiver account number from bank details\n",
    "    df[\"DifferentBenNum\"] = np.where(\n",
    "        df[\"Account_ben\"] == df[\"BeneficiaryAccount\"], 0, 1\n",
    "    )\n",
    "\n",
    "    # Different sender account name from bank details\n",
    "    df[\"DifferentOrderName\"] = np.where(\n",
    "        df[\"Name_order\"] == df[\"OrderingName\"], 0, 1\n",
    "    )\n",
    "    # Different receiver account name from bank details\n",
    "    df[\"DifferentBenName\"] = np.where(\n",
    "        df[\"Name_ben\"] == df[\"BeneficiaryName\"], 0, 1\n",
    "    )\n",
    "\n",
    "    # Different sender account ordering street from bank details\n",
    "    df[\"DifferentOrderStreet\"] = np.where(\n",
    "        df[\"Street_order\"] == df[\"OrderingStreet\"], 0, 1\n",
    "    )\n",
    "    # Different receiver account ordering street from bank details\n",
    "    df[\"DifferentBenStreet\"] = np.where(\n",
    "        df[\"Street_ben\"] == df[\"BeneficiaryStreet\"], 0, 1\n",
    "    )\n",
    "\n",
    "    # Different sender account country code/zip from bank details\n",
    "    df[\"DifferentOrderZip\"] = np.where(\n",
    "        df[\"CountryCityZip_order\"] == df[\"OrderingCountryCityZip\"], 0, 1\n",
    "    )\n",
    "    # Different receiver account country code/zip from bank details\n",
    "    df[\"DifferentBenZip\"] = np.where(\n",
    "        df[\"CountryCityZip_ben\"] == df[\"BeneficiaryCountryCityZip\"], 0, 1\n",
    "    )\n",
    "\n",
    "    # Some missing value treatment\n",
    "    df.loc[df[\"Flags_ben\"].isna(), \"Flags_ben\"] = 99\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e553d18a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4233669b",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "835a74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NN layers and other componenets.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "tf.random.set_seed(13) # to make sure the experiment is reproducible.\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "def build_model1_two_hidden_layers(normed_train_data):\n",
    "    # Keras model object created from Sequential class. This will be the container that contains all layers.\n",
    "    model = Sequential()\n",
    "\n",
    "    # The model so far is empty. It can be constructed by adding layers and compilation.\n",
    "    # This Keras model with multiple hidden layers.\n",
    "    \n",
    "    # Input Layer with 10 Neurons\n",
    "    model.add(Dense(128, input_shape = (normed_train_data.shape[1],)))    # Input layer => input_shape must be explicitly designated\n",
    "    \n",
    "#     model.add(Activation('relu')) # relu or sigmoid.\n",
    "#     model.add(Dense(128,Activation('relu')))                         # Hidden layer 1 => only output dimension should be designated (output dimension = # of Neurons = 50)\n",
    "    \n",
    "    model.add(Dense(1))                          # Output layer => output dimension = 1 since it is a regression problem\n",
    "    \n",
    "    # Activation: sigmoid, softmax, tanh, relu, LeakyReLU. \n",
    "    #Optimizer: SGD, Adam, RMSProp, etc. # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "    learning_rate = 0.0001\n",
    "    optimizer = optimizers.Nadam(learning_rate)\n",
    "#     optimizer = 'adam'\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy',tf.keras.metrics.Precision(),\n",
    "                                                                       tf.keras.metrics.Recall()]) \n",
    "    # for regression problems, mean squared error (MSE) is often employed\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21ff30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b443752",
   "metadata": {},
   "source": [
    "### Split into 2 clients using Sender data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f96450",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloaders=[]\n",
    "valloaders=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5351bcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPSUFRPP    1965697\n",
       "WVOLDEMM     700002\n",
       "ZOUOGB22     529859\n",
       "WITAZAJJ     514627\n",
       "ABVVUS6S     367029\n",
       "MRQHUS44     274065\n",
       "CBLHESMM      80990\n",
       "FAMAPEPL      73733\n",
       "HNYPITMM      49092\n",
       "BRRGPTPL      36690\n",
       "XAMTZWHX      33503\n",
       "DECKJPJJ      30108\n",
       "GDYCCHZZ      24060\n",
       "KNPVECEQ       9547\n",
       "MBYOTRIS       2699\n",
       "UNUSAL22         24\n",
       "Name: Sender, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset['Sender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cded67",
   "metadata": {},
   "source": [
    "Sender 'DPSUFRPP' contains almost 42% of the data. Hence they are considered as one client and the rest as another client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "658b22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainloadset,valloadset=train_test_split(trainset,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8787bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloaders.append(trainloadset[trainloadset['Sender']=='DPSUFRPP'])\n",
    "trainloaders.append(trainloadset[trainloadset['Sender']!='DPSUFRPP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b934d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "valloaders.append(valloadset[valloadset['Sender']=='DPSUFRPP'])\n",
    "valloaders.append(valloadset[valloadset['Sender']!='DPSUFRPP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f84908f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader=testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03f1e1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376172, 31)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainloaders[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd91919c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(705108, 31)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d61160",
   "metadata": {},
   "source": [
    "### Fit / Evaluate / Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "186a2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader,valloader,train_labels,valid_labels, epochs: int, verbose=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    batch_size=128\n",
    "    EPOCHS=2\n",
    "    normed_train_data=trainloader\n",
    "    normed_valid_dataset=valloader\n",
    "    history = model.fit(\n",
    "        normed_train_data, \n",
    "        train_labels,\n",
    "        batch_size = batch_size,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        steps_per_epoch = int(normed_train_data.shape[0] / batch_size) ,\n",
    "        validation_data = (normed_valid_dataset, valid_labels),   \n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "def test(model, testloader,test_labels):\n",
    "    normed_test_data=testloader\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    print('Test Split: ')\n",
    "    results =  model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "    print(model.metrics_names)\n",
    "    print(results)\n",
    "    #print(\"Accuracy   : {:5.2f} \".format(accuracy))\n",
    "\n",
    "\n",
    "from sklearn.metrics import (accuracy_score,classification_report,confusion_matrix)\n",
    "from sklearn import metrics\n",
    "\n",
    "def score_data(model, X_train_data, Y_train_data) -> None:\n",
    "\n",
    "    y_pred = model.predict(X_train_data)\n",
    "    ynew = np.round(y_pred).astype(int)\n",
    "    print(ynew)\n",
    "    print(\"AUPRC:\", metrics.average_precision_score(y_true=Y_train_data, y_score=ynew))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f3abc9",
   "metadata": {},
   "source": [
    "### Centralized result using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50e8dacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tl=data_prep1(trainloadset)\n",
    "vl=data_prep1(valloadset)\n",
    "testl=data_prep1(testloader)\n",
    "\n",
    "train_labels=tl.pop('Label')\n",
    "val_labels=vl.pop('Label')\n",
    "test_labels=testl.pop('Label')\n",
    "\n",
    "trainloader=norm(tl)\n",
    "valloader=norm(vl)\n",
    "testloader=norm(testl)\n",
    "\n",
    "model=build_model1_two_hidden_layers(trainloader)\n",
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1175e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25657/25657 [==============================] - 117s 4ms/step - loss: 0.0161 - accuracy: 0.9990 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0164 - val_accuracy: 0.9989 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/2\n",
      "25657/25657 [==============================] - 113s 4ms/step - loss: 0.0156 - accuracy: 0.9990 - precision: 1.0000 - recall: 0.0012 - val_loss: 0.0149 - val_accuracy: 0.9989 - val_precision: 1.0000 - val_recall: 0.0120\n",
      "Test Split: \n",
      "22035/22035 - 55s - loss: 0.0164 - accuracy: 0.9989 - precision: 0.0000e+00 - recall: 0.0000e+00 - 55s/epoch - 2ms/step\n",
      "['loss', 'accuracy', 'precision', 'recall']\n",
      "[0.016425862908363342, 0.998920738697052, 0.0, 0.0]\n",
      "22035/22035 [==============================] - 47s 2ms/step\n",
      "[[ 0]\n",
      " [-1]\n",
      " [-2]\n",
      " ...\n",
      " [-2]\n",
      " [-2]\n",
      " [-1]]\n",
      "AUPRC: 0.0013424172080825011\n"
     ]
    }
   ],
   "source": [
    "train(model, trainloader,valloader,train_labels,val_labels, 1)\n",
    "\n",
    "test(model, testloader,test_labels)\n",
    "\n",
    "score_data(model,testloader,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb6f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8ae05e9",
   "metadata": {},
   "source": [
    "### For Split 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ca2e57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\328108437.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"hour\"] = df[\"Timestamp\"].dt.hour\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\328108437.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"hour\"] = df[\"Timestamp\"].dt.hour\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10751/10751 [==============================] - 50s 4ms/step - loss: 0.0216 - accuracy: 0.9986 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.9985 - val_precision: 0.2000 - val_recall: 0.0012\n",
      "Epoch 2/2\n",
      "10751/10751 [==============================] - 46s 4ms/step - loss: 0.0216 - accuracy: 0.9986 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.9985 - val_precision: 0.2000 - val_recall: 0.0012\n",
      "Test Split: \n",
      "22035/22035 - 53s - loss: 0.0164 - accuracy: 0.9989 - precision: 0.0000e+00 - recall: 0.0000e+00 - 53s/epoch - 2ms/step\n",
      "['loss', 'accuracy', 'precision', 'recall']\n",
      "[0.016449233517050743, 0.998920738697052, 0.0, 0.0]\n",
      "22035/22035 [==============================] - 46s 2ms/step\n",
      "[[ 0]\n",
      " [-1]\n",
      " [-2]\n",
      " ...\n",
      " [-2]\n",
      " [-2]\n",
      " [-1]]\n",
      "AUPRC: 0.0013526509302489225\n"
     ]
    }
   ],
   "source": [
    "tl=data_prep1(trainloaders[0])\n",
    "vl=data_prep1(valloaders[0])\n",
    "\n",
    "train_labels=tl.pop('Label')\n",
    "val_labels=vl.pop('Label')\n",
    "\n",
    "trainloader=(tl)\n",
    "valloader=(vl)\n",
    "\n",
    "train(model, trainloader,valloader,train_labels,val_labels, 1)\n",
    "\n",
    "test(model, testloader,test_labels)\n",
    "\n",
    "score_data(model,testloader,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e6a021",
   "metadata": {},
   "source": [
    "### For Split 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "294dc0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\328108437.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"hour\"] = df[\"Timestamp\"].dt.hour\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\328108437.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"hour\"] = df[\"Timestamp\"].dt.hour\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
      "C:\\Users\\rahul.karuparthi\\AppData\\Local\\Temp\\ipykernel_18440\\143421382.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "14906/14906 [==============================] - 65s 4ms/step - loss: 0.0121 - accuracy: 0.9992 - precision: 0.2500 - recall: 6.6800e-04 - val_loss: 0.0120 - val_accuracy: 0.9992 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/2\n",
      "14906/14906 [==============================] - 66s 4ms/step - loss: 0.0121 - accuracy: 0.9992 - precision: 0.2500 - recall: 6.6800e-04 - val_loss: 0.0120 - val_accuracy: 0.9992 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Test Split: \n",
      "22035/22035 - 51s - loss: 0.0164 - accuracy: 0.9989 - precision: 0.0000e+00 - recall: 0.0000e+00 - 51s/epoch - 2ms/step\n",
      "['loss', 'accuracy', 'precision', 'recall']\n",
      "[0.016449233517050743, 0.998920738697052, 0.0, 0.0]\n",
      "22035/22035 [==============================] - 51s 2ms/step\n",
      "[[ 0]\n",
      " [-1]\n",
      " [-2]\n",
      " ...\n",
      " [-2]\n",
      " [-2]\n",
      " [-1]]\n",
      "AUPRC: 0.0013526509302489225\n"
     ]
    }
   ],
   "source": [
    "tl=data_prep1(trainloaders[1])\n",
    "vl=data_prep1(valloaders[1])\n",
    "\n",
    "train_labels=tl.pop('Label')\n",
    "val_labels=vl.pop('Label')\n",
    "\n",
    "trainloader=(tl)\n",
    "valloader=(vl)\n",
    "\n",
    "train(model, trainloader,valloader,train_labels,val_labels, 1)\n",
    "\n",
    "test(model, testloader,test_labels)\n",
    "\n",
    "score_data(model,testloader,test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
