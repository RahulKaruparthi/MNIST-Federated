{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea816a14",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409e6f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# import pandas\n",
    "import json\n",
    "\n",
    "# from sklearn.externals import joblib\n",
    "import pickle\n",
    "from importlib.resources import path\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.utils\n",
    "from pandas import Int64Index, MultiIndex\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec1dd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\fincrime-federated\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "dirname = os.path.dirname('D:/fincrime-federated/')\n",
    "os.chdir(dirname)\n",
    "print(os.getcwd())\n",
    "\n",
    "import submission_src.fincrime.solution_centralized as funcs\n",
    "importlib.reload(funcs) \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model_dir = 'D:/fincrime-federated/model/fincrime'\n",
    "preds_format_path = 'D:/fincrime-federated/prediction/fincrime/prediction_format'\n",
    "preds_dest_path = 'D:/fincrime-federated/prediction/fincrime/prediction'\n",
    "\n",
    "\n",
    "## train on data\n",
    "datapathjsonString = 'data/fincrime/centralized/train/data.json'\n",
    "swift_data_path = funcs.json_to_dict(datapathjsonString)['swift_data_path']\n",
    "bank_data_path = funcs.json_to_dict(datapathjsonString)['bank_data_path']\n",
    "\n",
    "# trainset = funcs.fit(swift_data_path = swift_data_path,\n",
    "#                     bank_data_path = bank_data_path,\n",
    "#                     model_dir = model_dir,\n",
    "#                     preds_format_path = preds_format_path,\n",
    "#                     preds_dest_path = preds_dest_path,\n",
    "#                     m = 'xgboost')\n",
    "def json_to_dict(datapathjsonString):\n",
    "    datapathJson = open(datapathjsonString)\n",
    "    datapathDict = json.load(datapathJson)\n",
    "    return datapathDict\n",
    "\n",
    "\n",
    "def load_data(swift_data_path, bank_data_path):\n",
    "    swift_data = pd.read_csv(swift_data_path, index_col=\"MessageId\")\n",
    "    swift_data[\"Timestamp\"] = swift_data[\"Timestamp\"].astype(\"datetime64[ns]\")\n",
    "    bank_data = pd.read_csv(bank_data_path)\n",
    "    return swift_data, bank_data\n",
    "\n",
    "train_data, bank_data = load_data(\n",
    "    swift_data_path=swift_data_path, bank_data_path=bank_data_path\n",
    ")\n",
    "\n",
    "# Merging with bank details\n",
    "train_data = pd.merge(\n",
    "    train_data,\n",
    "    bank_data,\n",
    "    left_on=\"OrderingAccount\",\n",
    "    right_on=\"Account\",\n",
    "    how=\"left\",\n",
    ")\n",
    "train_data = pd.merge(\n",
    "    train_data,\n",
    "    bank_data,\n",
    "    left_on=\"BeneficiaryAccount\",\n",
    "    right_on=\"Account\",\n",
    "    how=\"left\",\n",
    "    suffixes=[\"_order\", \"_ben\"],\n",
    ")\n",
    "trainset = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4cbf92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Total time taken  95.61597180366516  seconds\n"
     ]
    }
   ],
   "source": [
    "# predict on test data\n",
    "import submission_src.fincrime.solution_centralized as funcs\n",
    "importlib.reload(funcs) \n",
    "\n",
    "datapathjsonString = 'data/fincrime/centralized/test/data.json'\n",
    "swift_data_path = funcs.json_to_dict(datapathjsonString)['swift_data_path']\n",
    "bank_data_path = funcs.json_to_dict(datapathjsonString)['bank_data_path']\n",
    "\n",
    "# testset = funcs.predict(\n",
    "#                     swift_data_path =swift_data_path,\n",
    "#                     bank_data_path = bank_data_path,\n",
    "#                     model_dir = model_dir,\n",
    "#                     preds_format_path = preds_format_path,\n",
    "#                     preds_dest_path = preds_dest_path,\n",
    "#                     m = 'xgboost'\n",
    "#                     )   \n",
    "\n",
    "test_data, bank_data = load_data(\n",
    "    swift_data_path=swift_data_path, bank_data_path=bank_data_path\n",
    ")\n",
    "print(test_data['Sender'].nunique())\n",
    "# Merging with bank details\n",
    "test_data = pd.merge(\n",
    "    test_data,\n",
    "    bank_data,\n",
    "    left_on=\"OrderingAccount\",\n",
    "    right_on=\"Account\",\n",
    "    how=\"left\",\n",
    ")\n",
    "test_data = pd.merge(\n",
    "    test_data,\n",
    "    bank_data,\n",
    "    left_on=\"BeneficiaryAccount\",\n",
    "    right_on=\"Account\",\n",
    "    how=\"left\",\n",
    "    suffixes=[\"_order\", \"_ben\"],\n",
    ")\n",
    "\n",
    "testset = test_data\n",
    "\n",
    "print(\"Total time taken \", (time.time() - start_time),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a25f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset['Sender'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91fe49e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testset.head(1)\n",
    "testset['Sender'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdfe7ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4691725, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "777e901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsett = trainset.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8345eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(705108, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84873580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98118, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.dropna(axis=0,how='any',inplace=True)\n",
    "testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd877970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4686615\n",
       "1       4686\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c737ea",
   "metadata": {},
   "source": [
    "### Sliced the dataset below (as facing Memory error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c029313",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset1=trainset.iloc[0:25000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3bc6b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa557a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset1 = testset.iloc[10000:25000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "719bdb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98118, 31)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "786b7bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24961\n",
       "1       39\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset1['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01237c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swift_bank_df_22=testset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1326b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = trainset1.pop('Label')\n",
    "# test_labels = testset1.pop('Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29948744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(train_dataset):\n",
    "    train_stats = train_dataset.describe()\n",
    "    train_stats = train_stats.transpose()\n",
    "    return train_stats\n",
    "\n",
    "def norm(x):\n",
    "    train_stats=stats(x)\n",
    "    return (x - train_stats['mean']) / train_stats['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d4d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b35aa747",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fd2db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_by_features(\n",
    "    df,\n",
    "    level_1,\n",
    "    level_2,\n",
    "    model_dir,\n",
    "    save_as_object=False,\n",
    "    map_from_train_set=False,\n",
    ") -> None:\n",
    "\n",
    "    if map_from_train_set == True:\n",
    "\n",
    "        level_1_level_2_frequency = pickle.load(\n",
    "            open(\n",
    "                model_dir\n",
    "                + \"/\"\n",
    "                + str(level_1 + \"_\" + level_2 + \"_frequency\")\n",
    "                + \".sav\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        _level_1 = df.loc[:, level_1].unique()\n",
    "        _level_2 = df.loc[:, level_2].unique()\n",
    "        df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
    "            :, level_2\n",
    "        ].astype(str)\n",
    "        df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
    "            :, str(level_1 + \"_\" + level_2)\n",
    "        ].map(level_1_level_2_frequency)\n",
    "    else:\n",
    "        _level_1 = df.loc[:, level_1].unique()\n",
    "        _level_2 = df.loc[:, level_2].unique()\n",
    "        df[str(level_1 + \"_\" + level_2)] = df.loc[:, level_1] + df.loc[\n",
    "            :, level_2\n",
    "        ].astype(str)\n",
    "        level_1_level_2_frequency = {}\n",
    "        for s in _level_1:\n",
    "            level_1_rows = df[df[level_1] == s]\n",
    "            for h in _level_2:\n",
    "                level_1_level_2_frequency[s + str(h)] = len(\n",
    "                    level_1_rows[level_1_rows.loc[:, level_2] == h]\n",
    "                )\n",
    "\n",
    "        df.loc[:, str(level_1 + \"_\" + level_2 + \"_frequency\")] = df.loc[\n",
    "            :, str(level_1 + \"_\" + level_2)\n",
    "        ].map(level_1_level_2_frequency)\n",
    "\n",
    "        if save_as_object == True:\n",
    "            pickle.dump(\n",
    "                level_1_level_2_frequency,\n",
    "                open(\n",
    "                    model_dir\n",
    "                    + \"/\"\n",
    "                    + str(level_1 + \"_\" + level_2 + \"_frequency\")\n",
    "                    + \".sav\",\n",
    "                    \"wb\",\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cbc173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep1(train_data):\n",
    "    # Feature engineering\n",
    "#     train_data = train_data.dropna(axis=0)\n",
    "    \n",
    "#     warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "    import warnings\n",
    "\n",
    "    import pandas as pd\n",
    "    from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "    warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "    \n",
    "    train_data = create_features(\n",
    "        df=train_data, model_dir=model_dir, map_from_train_set=False\n",
    "    )\n",
    "\n",
    "    # Keep below columns for training and testing\n",
    "    cols_to_keep = [\n",
    "        \"SettlementAmount\",\n",
    "        \"InstructedAmount\",\n",
    "        \"Label\",\n",
    "        \"hour\",\n",
    "        \"Flags_ben\",\n",
    "        \"MissingBenAccount\",\n",
    "        \"MissingOrdAccount\",\n",
    "        \"Sender_hour_frequency\",\n",
    "        # 'sender_currency_amount_average',\n",
    "        \"Sender_Receiver_frequency\",\n",
    "        \"Sender_InstructedCurrency_frequency\",\n",
    "        \"seq\",\n",
    "        # 'receiver_transactions',\n",
    "        \"Receiver_SettlementCurrency_frequency\",\n",
    "        \"Receiver_hour_frequency\",\n",
    "        \"DifferentOrderNum\",\n",
    "        \"DifferentBenNum\",\n",
    "        \"DifferentOrderName\",\n",
    "        \"DifferentBenName\",\n",
    "        \"DifferentOrderStreet\",\n",
    "        \"DifferentBenStreet\",\n",
    "        \"DifferentOrderZip\",\n",
    "        \"DifferentBenZip\",\n",
    "    ]\n",
    "\n",
    "    train_data_2 = train_data[cols_to_keep]\n",
    "    return train_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56b66cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep2(train_data):\n",
    "    # Feature engineering\n",
    "#     train_data = train_data.dropna(axis=0)\n",
    "    train_data = create_features(\n",
    "        df=train_data, model_dir=model_dir, map_from_train_set=True\n",
    "    )\n",
    "\n",
    "    # Keep below columns for training and testing\n",
    "    cols_to_keep = [\n",
    "        \"SettlementAmount\",\n",
    "        \"InstructedAmount\",\n",
    "        \"Label\",\n",
    "        \"hour\",\n",
    "        \"Flags_ben\",\n",
    "        \"MissingBenAccount\",\n",
    "        \"MissingOrdAccount\",\n",
    "        \"Sender_hour_frequency\",\n",
    "        # 'sender_currency_amount_average',\n",
    "        \"Sender_Receiver_frequency\",\n",
    "        \"Sender_InstructedCurrency_frequency\",\n",
    "        \"seq\",\n",
    "        # 'receiver_transactions',\n",
    "        \"Receiver_SettlementCurrency_frequency\",\n",
    "        \"Receiver_hour_frequency\",\n",
    "        \"DifferentOrderNum\",\n",
    "        \"DifferentBenNum\",\n",
    "        \"DifferentOrderName\",\n",
    "        \"DifferentBenName\",\n",
    "        \"DifferentOrderStreet\",\n",
    "        \"DifferentBenStreet\",\n",
    "        \"DifferentOrderZip\",\n",
    "        \"DifferentBenZip\",\n",
    "    ]\n",
    "\n",
    "    train_data_2 = train_data[cols_to_keep]\n",
    "    return train_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e26e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, model_dir, map_from_train_set=False):\n",
    "\n",
    "    ## Feature Engineering\n",
    "\n",
    "    # Hour column\n",
    "    df[\"hour\"] = df[\"Timestamp\"].dt.hour\n",
    "\n",
    "    # Hour frequency for each sender\n",
    "    freq_by_features(\n",
    "        df=df,\n",
    "        level_1=\"Sender\",\n",
    "        level_2=\"hour\",\n",
    "        model_dir=model_dir,\n",
    "        save_as_object=True,\n",
    "        map_from_train_set=map_from_train_set,\n",
    "    )\n",
    "    # Hour frequency for each receiver\n",
    "    freq_by_features(\n",
    "        df=df,\n",
    "        level_1=\"Receiver\",\n",
    "        level_2=\"hour\",\n",
    "        model_dir=model_dir,\n",
    "        save_as_object=True,\n",
    "        map_from_train_set=map_from_train_set,\n",
    "    )\n",
    "    # Sender-Currency Frequency\n",
    "    freq_by_features(\n",
    "        df=df,\n",
    "        level_1=\"Sender\",\n",
    "        level_2=\"InstructedCurrency\",\n",
    "        model_dir=model_dir,\n",
    "        save_as_object=True,\n",
    "        map_from_train_set=map_from_train_set,\n",
    "    )\n",
    "    # Receiver-SettledCurrency Frequency\n",
    "    freq_by_features(\n",
    "        df=df,\n",
    "        level_1=\"Receiver\",\n",
    "        level_2=\"SettlementCurrency\",\n",
    "        model_dir=model_dir,\n",
    "        save_as_object=True,\n",
    "        map_from_train_set=map_from_train_set,\n",
    "    )\n",
    "    # Sender-Receiver Frequency\n",
    "    freq_by_features(\n",
    "        df=df,\n",
    "        level_1=\"Sender\",\n",
    "        level_2=\"Receiver\",\n",
    "        model_dir=model_dir,\n",
    "        save_as_object=True,\n",
    "        map_from_train_set=map_from_train_set,\n",
    "    )\n",
    "\n",
    "    # # Average Amount per Sender-Currency - not working\n",
    "    # Sender_ICurrency_mean = mean_by_features(df = df, level_1=\"Sender\" , level_2=\"InstructedCurrency\")\n",
    "    # df.loc[:,\"Sender_ICurrency_mean\"] = \\\n",
    "    #     df.loc[:,\"Sender_InstructedCurrency\"].map(Sender_ICurrency_mean)\n",
    "\n",
    "    # Numbering the transactions within a account order - ben - date combination\n",
    "    df = df.sort_values(\n",
    "        by=[\n",
    "            \"SettlementDate\",\n",
    "            \"Sender\",\n",
    "            \"Receiver\",\n",
    "            \"Account_order\",\n",
    "            \"Account_ben\",\n",
    "            \"Timestamp\",\n",
    "        ],\n",
    "        ascending=True,\n",
    "    )\n",
    "    df[\"seq\"] = (\n",
    "        df.groupby(\n",
    "            [\n",
    "                \"SettlementDate\",\n",
    "                \"Sender\",\n",
    "                \"Receiver\",\n",
    "                \"Account_order\",\n",
    "                \"Account_ben\",\n",
    "            ]\n",
    "        ).cumcount()\n",
    "        + 1\n",
    "    )\n",
    "    df[\"seq\"] = df[\"seq\"].replace(np.NAN, 1)\n",
    "\n",
    "    # Flag columns for transactions with missing bank details\n",
    "    df[[\"MissingBenAccount\"]] = 0\n",
    "    df.loc[df[\"Flags_ben\"].isnull(), \"MissingBenAccount\"] = 1\n",
    "    df[[\"MissingOrdAccount\"]] = 0\n",
    "    df.loc[df[\"Flags_order\"].isnull(), \"MissingOrdAccount\"] = 1\n",
    "\n",
    "    # Different sender account number from bank details\n",
    "    df[\"DifferentOrderNum\"] = np.where(\n",
    "        df[\"Account_order\"] == df[\"OrderingAccount\"], 0, 1\n",
    "    )\n",
    "    # Different receiver account number from bank details\n",
    "    df[\"DifferentBenNum\"] = np.where(\n",
    "        df[\"Account_ben\"] == df[\"BeneficiaryAccount\"], 0, 1\n",
    "    )\n",
    "\n",
    "    # Different sender account name from bank details\n",
    "    df[\"DifferentOrderName\"] = np.where(\n",
    "        df[\"Name_order\"] == df[\"OrderingName\"], 0, 1\n",
    "    )\n",
    "    # Different receiver account name from bank details\n",
    "    df[\"DifferentBenName\"] = np.where(\n",
    "        df[\"Name_ben\"] == df[\"BeneficiaryName\"], 0, 1\n",
    "    )\n",
    "\n",
    "    # Different sender account ordering street from bank details\n",
    "    df[\"DifferentOrderStreet\"] = np.where(\n",
    "        df[\"Street_order\"] == df[\"OrderingStreet\"], 0, 1\n",
    "    )\n",
    "    # Different receiver account ordering street from bank details\n",
    "    df[\"DifferentBenStreet\"] = np.where(\n",
    "        df[\"Street_ben\"] == df[\"BeneficiaryStreet\"], 0, 1\n",
    "    )\n",
    "\n",
    "    # Different sender account country code/zip from bank details\n",
    "    df[\"DifferentOrderZip\"] = np.where(\n",
    "        df[\"CountryCityZip_order\"] == df[\"OrderingCountryCityZip\"], 0, 1\n",
    "    )\n",
    "    # Different receiver account country code/zip from bank details\n",
    "    df[\"DifferentBenZip\"] = np.where(\n",
    "        df[\"CountryCityZip_ben\"] == df[\"BeneficiaryCountryCityZip\"], 0, 1\n",
    "    )\n",
    "\n",
    "    # Some missing value treatment\n",
    "    df.loc[df[\"Flags_ben\"].isna(), \"Flags_ben\"] = 99\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e553d18a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4233669b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7d87a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=(28,28)),\n",
    "#     keras.layers.Dense(128, activation='relu'),\n",
    "#     keras.layers.Dense(256, activation='relu'),\n",
    "#     keras.layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "# model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "835a74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NN layers and other componenets.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "tf.random.set_seed(13) # to make sure the experiment is reproducible.\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "def build_model1_two_hidden_layers(normed_train_data):\n",
    "    # Keras model object created from Sequential class. This will be the container that contains all layers.\n",
    "    model = Sequential()\n",
    "\n",
    "    # The model so far is empty. It can be constructed by adding layers and compilation.\n",
    "    # This Keras model with multiple hidden layers.\n",
    "    \n",
    "    # Input Layer with 10 Neurons\n",
    "    model.add(Dense(32, input_shape = (normed_train_data.shape[1],)))    # Input layer => input_shape must be explicitly designated\n",
    "#     model.add(Activation('relu')) # relu or sigmoid.\n",
    "    \n",
    "#     model.add(Dense(128,Activation('relu')))                         # Hidden layer 1 => only output dimension should be designated (output dimension = # of Neurons = 50)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Dense(1))                          # Output layer => output dimension = 1 since it is a regression problem\n",
    "    \n",
    "    # Activation: sigmoid, softmax, tanh, relu, LeakyReLU. \n",
    "    #Optimizer: SGD, Adam, RMSProp, etc. # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "    learning_rate = 0.0001\n",
    "#     optimizer = optimizers.Nadam(learning_rate)\n",
    "    optimizer = 'adam'\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy',tf.keras.metrics.Precision(),\n",
    "                                                                       tf.keras.metrics.Recall()]) \n",
    "    # for regression problems, mean squared error (MSE) is often employed\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21ff30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e740a239",
   "metadata": {},
   "source": [
    "# Fed Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "451f2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from flwr.common import Metrics\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2e50321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 1.13.0+cpu and Flower 1.1.0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f58e5e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98118"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b443752",
   "metadata": {},
   "source": [
    "#### Split into 10 clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd99b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS=2\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbc526d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4691301"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a11eefa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def load_datasets():\n",
    "#     # Download and transform CIFAR-10 (train and test)\n",
    "\n",
    "#     trainloadset,valloadset=train_test_split(trainset,test_size=0.3)\n",
    "#     testset2=testset\n",
    "#     print(\"length of Trainset=\",len(trainloadset))\n",
    "#     print(\"length of Valset=\",len(valloadset))\n",
    "#     print(\"length of Testset=\",len(testset2))\n",
    "#     le1=len(trainloadset)//10\n",
    "#     le2=len(valloadset)//10\n",
    "    \n",
    "#     trainloaders=[]\n",
    "#     valloaders=[]\n",
    "#     for i in range(1,NUM_CLIENTS+1):\n",
    "#         temp_df1=trainloadset.head(le1)\n",
    "#         trainloadset=trainloadset.tail(len(trainloadset)-le1)\n",
    "#         temp_df2=valloadset.head(le2)\n",
    "#         valloadset=valloadset.tail(len(valloadset)-le2)\n",
    "#         trainloaders.append(temp_df1)\n",
    "#         valloaders.append(temp_df2)\n",
    "    \n",
    "        \n",
    "    \n",
    "#     return trainloaders, valloaders, testset2\n",
    "\n",
    "# trainloaders, valloaders, testloader = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9619dca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3f96450",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloaders=[]\n",
    "valloaders=[]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainloadset,valloadset=train_test_split(trainset,test_size=0.3)\n",
    "\n",
    "trainloaders.append(trainloadset[trainloadset['Sender']=='DPSUFRPP'])\n",
    "trainloaders.append(trainloadset[trainloadset['Sender']!='DPSUFRPP'])\n",
    "\n",
    "valloaders.append(valloadset[valloadset['Sender']=='DPSUFRPP'])\n",
    "valloaders.append(valloadset[valloadset['Sender']!='DPSUFRPP'])\n",
    "\n",
    "testloader=testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb684d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4691301, 31)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03f1e1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1375359, 31)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainloaders[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd91919c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98118, 31)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cca196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "186a2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader,valloader,train_labels,valid_labels, epochs: int, verbose=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    batch_size=128\n",
    "    EPOCHS=2\n",
    "    normed_train_data=trainloader\n",
    "    normed_valid_dataset=valloader\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight('balanced',np.unique(train_labels),train_labels)\n",
    "\n",
    "    history = model.fit(\n",
    "        normed_train_data, \n",
    "        train_labels,\n",
    "        batch_size = batch_size,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        steps_per_epoch = int(normed_train_data.shape[0] / batch_size) ,\n",
    "        validation_data = (normed_valid_dataset, valid_labels),   \n",
    "        class_weight=class_weights,\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "def test(model, testloader,test_labels):\n",
    "    normed_test_data=testloader\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    print('Test Split: ')\n",
    "    results =  model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "    print(model.metrics_names)\n",
    "    print(results)\n",
    "    #print(\"Accuracy   : {:5.2f} \".format(accuracy))\n",
    "\n",
    "\n",
    "from sklearn.metrics import (accuracy_score,classification_report,confusion_matrix)\n",
    "from sklearn import metrics\n",
    "\n",
    "def score_data(model, X_train_data, Y_train_data) -> None:\n",
    "\n",
    "#     pred = model.predict(X_train_data[:1])\n",
    "    scaler.fit(X_train_data)\n",
    "    Xnew = scaler.transform(X_train_data)\n",
    "    \n",
    "    y_pred = model.predict(Xnew)\n",
    "    ynew = np.round(y_pred).astype(int)\n",
    "    print(\"AUPRC:\", metrics.average_precision_score(y_true=Y_train_data, y_score=ynew))\n",
    "    \n",
    "#     prediction = model.predict(x_test[:1])\n",
    "    print(\"prediction shape:\", pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70b0380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler(quantile_range=(25, 75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830bb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13f3abc9",
   "metadata": {},
   "source": [
    "### Centralized result using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50e8dacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "compute_class_weight() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(trainloader)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m test(model, testloader,test_labels)\n\u001b[0;32m     18\u001b[0m score_data(model,testloader,test_labels)\n",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, trainloader, valloader, train_labels, valid_labels, epochs, verbose)\u001b[0m\n\u001b[0;32m      5\u001b[0m normed_train_data\u001b[38;5;241m=\u001b[39mtrainloader\n\u001b[0;32m      6\u001b[0m normed_valid_dataset\u001b[38;5;241m=\u001b[39mvalloader\n\u001b[1;32m----> 8\u001b[0m class_weights \u001b[38;5;241m=\u001b[39m \u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbalanced\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     11\u001b[0m     normed_train_data, \n\u001b[0;32m     12\u001b[0m     train_labels,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weights,\n\u001b[0;32m     20\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: compute_class_weight() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "tl=data_prep1(trainloaders[0])\n",
    "vl=data_prep1(valloaders[0])\n",
    "testl=data_prep1(testloader)\n",
    "train_labels=tl.pop('Label')\n",
    "val_labels=vl.pop('Label')\n",
    "test_labels=testl.pop('Label')\n",
    "trainloader=(tl)\n",
    "valloader=(vl)\n",
    "testloader=(testl)\n",
    "model=build_model1_two_hidden_layers(trainloader)\n",
    "model.save(\"my_model\")\n",
    "# print(trainloader)\n",
    "\n",
    "train(model, trainloader,valloader,train_labels,val_labels, 1)\n",
    "\n",
    "test(model, testloader,test_labels)\n",
    "\n",
    "score_data(model,testloader,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4267ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b5652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01ba1867",
   "metadata": {},
   "source": [
    "#### Alternate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb11005",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl=data_prep1(trainloaders[1])\n",
    "vl=data_prep1(valloaders[1])\n",
    "# testl=data_prep1(testloader)\n",
    "train_labels=tl.pop('Label')\n",
    "val_labels=vl.pop('Label')\n",
    "# test_labels=testl.pop('Label')\n",
    "trainloader=(tl)\n",
    "valloader=(vl)\n",
    "# testloader=(testl)\n",
    "train(model, trainloader,valloader,train_labels,val_labels, 1)\n",
    "\n",
    "test(model, testloader,test_labels)\n",
    "\n",
    "score_data(model,testloader,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512551b9",
   "metadata": {},
   "source": [
    "### Centralized results using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d5e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=data_prep1(trainset)\n",
    "\n",
    "# y_train = train_set.pop('Label')\n",
    "y_train = train_set[\"Label\"].values\n",
    "X_train = train_set.drop([\"Label\"], axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c45269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train_data, Y_train_data, m) -> None:\n",
    "    if m == \"rf\":\n",
    "        model = RandomForestClassifier(max_depth=7, random_state=0, n_estimators=10)\n",
    "    elif m == \"xgboost\":\n",
    "        model = XGBClassifier(n_estimators=100)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "#     cv_results = cross_val_score(model, X_train_data, Y_train_data, cv=kfold, scoring=\"f1\")\n",
    "    model.fit(X_train_data, Y_train_data)\n",
    "#     print(\"Minimum:\", cv_results.min())\n",
    "#     print(\"Maximum:\", cv_results.max())\n",
    "#     print(\"StanDev:\", cv_results.std())\n",
    "    return model\n",
    "\n",
    "def scoredata(X_train_data, Y_train_data, model, m) -> None:\n",
    "    pred = model.predict(X_train_data)\n",
    "#     print(m + \" Classification Report=\\n\\n\",classification_report(Y_train_data, pred))\n",
    "#     print(m + \" Confusion Matrix=\\n\\n\", confusion_matrix(Y_train_data, pred))\n",
    "    pred_proba = model.predict_proba(X_train_data)[:, 1]\n",
    "    print(\"AUPRC:\",metrics.average_precision_score(y_true=Y_train_data, y_score=pred_proba),)\n",
    "    return pred, pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f13e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.utils\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    ShuffleSplit,\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd4343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "# scaler = QuantileTransformer(output_distribution=\"uniform\")\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler(quantile_range=(25, 75))\n",
    "scaler.fit(X_train)\n",
    "tl = scaler.transform(X_train)\n",
    "test_loader = scaler.transform(testl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model on data        train_model(X_train_data=tl, Y_train_data=y_train, m='rf')\n",
    "model = RandomForestClassifier(max_depth=7, random_state=0, n_estimators=10)\n",
    "# kfold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "# cv_results = cross_val_score(model, X_train_data=tl, Y_train_data=y_train, cv=kfold, scoring=\"f1\")\n",
    "model.fit(tl, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2248c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = scaler.transform(testl)\n",
    "pred, pred_proba = scoredata(X_train_data=test_loader,Y_train_data=test_labels,model=model,m='rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3975983",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e383bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3380d06c",
   "metadata": {},
   "source": [
    "# MNist Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union, List\n",
    "XY = Tuple[np.ndarray, np.ndarray]\n",
    "Dataset = Tuple[XY, XY]\n",
    "LogRegParams = Union[XY, Tuple[np.ndarray]]\n",
    "XYList = List[XY]\n",
    "\n",
    "def get_model_parameters(model: LogisticRegression) -> LogRegParams:\n",
    "    \"\"\"Returns the paramters of a sklearn LogisticRegression model.\"\"\"\n",
    "    if model.fit_intercept:\n",
    "        params = [\n",
    "            model.coef_,\n",
    "            model.intercept_,\n",
    "        ]\n",
    "    else:\n",
    "        params = [\n",
    "            model.coef_,\n",
    "        ]\n",
    "    return params\n",
    "\n",
    "def set_model_params(\n",
    "    model: LogisticRegression, params: LogRegParams\n",
    ") -> LogisticRegression:\n",
    "    \"\"\"Sets the parameters of a sklean LogisticRegression model.\"\"\"\n",
    "    model.coef_ = params[0]\n",
    "    if model.fit_intercept:\n",
    "        model.intercept_ = params[1]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93781202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Flower client\n",
    "class MnistClient(fl.client.NumPyClient):\n",
    "    def get_parameters(self, config):  # type: ignore\n",
    "        return utils.get_model_parameters(model)\n",
    "\n",
    "    def fit(self, parameters, config):  # type: ignore\n",
    "        utils.set_model_params(model, parameters)\n",
    "        # Ignore convergence failure due to low local epochs\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            model.fit(X_train, y_train)\n",
    "        print(f\"Training finished for round {config['server_round']}\")\n",
    "        return utils.get_model_parameters(model), len(X_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):  # type: ignore\n",
    "        utils.set_model_params(model, parameters)\n",
    "        loss = log_loss(y_test, model.predict_proba(X_test))\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        return loss, len(X_test), {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)# class SaveModelStrategy(fl.server.strategy.FedAvg):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a858e",
   "metadata": {},
   "source": [
    "## NumpyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, trainloader, valloader):\n",
    "        self.model = model\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        \n",
    "    def get_parameters(self,config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        model.set_weights(parameters)\n",
    "        tl=data_prep1(self.trainloader)\n",
    "        vl=data_prep1(self.valloader)\n",
    "        train_labels=tl.pop('Label')\n",
    "        val_labels=vl.pop('Label')\n",
    "        test_labels=testl.pop('Label')\n",
    "        trainloader=(tl)\n",
    "        valloader=(vl)\n",
    "        train(self.model,trainloader,valloader,train_labels,val_labels, 1)\n",
    "        return model.get_weights(), len(x_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        model.set_weights(parameters)\n",
    "        results = model.evaluate(testloader, test_labels, verbose=0)\n",
    "#         loss, accuracy = model.evaluate(testloader, test_labels, verbose=0)\n",
    "#         results =  model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "        pred = model.predict(test_loader)\n",
    "#         print(pred)\n",
    "        auprc = metrics.average_precision_score(y_true=test_labels, y_score=pred)\n",
    "        print(\"AUPRC:\", auprc)\n",
    "        print(\"Eval accuracy : \", results[1])\n",
    "        loss = results[0]\n",
    "        return float(loss), len(x_test), {\"accuracy\": results[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    loaded_model = keras.models.load_model(\"my_model\")\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return FlowerClient(loaded_model, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e8d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "        fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "        min_fit_clients=2,  # Never sample less than 10 clients for training\n",
    "        min_evaluate_clients=1,  # Never sample less than 5 clients for evaluation\n",
    "        min_available_clients=2,  # Wait until all 10 clients are available\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=2,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    #strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51fa2e",
   "metadata": {},
   "source": [
    "## Weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf06a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84956a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=0.8,\n",
    "        fraction_evaluate=0.5,\n",
    "        min_fit_clients=2,\n",
    "        min_evaluate_clients=1,\n",
    "        min_available_clients=2,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea76fce",
   "metadata": {},
   "source": [
    "## FedAdagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FedAdam strategy\n",
    "strategy=fl.server.strategy.FedAdagrad(\n",
    "    fraction_fit=1,\n",
    "    fraction_evaluate=0.5,\n",
    "    min_fit_clients=10,\n",
    "    min_evaluate_clients=5,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(model.get_weights()),\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da871daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_config(server_round: int):\n",
    "    config = {\n",
    "        \"server_round\": server_round,\n",
    "        \"local_epochs\": 2,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.025,  # Train on 25 clients (each round)\n",
    "    fraction_evaluate=0.05,  # Evaluate on 50 clients (each round)\n",
    "    min_fit_clients=5,\n",
    "    min_evaluate_clients=10,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    "    on_fit_config_fn=fit_config,\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd6c01",
   "metadata": {},
   "source": [
    "## FedCustom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e0d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Union\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    MetricsAggregationFn,\n",
    "    NDArrays,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "\n",
    "\n",
    "class FedCustom(fl.server.strategy.Strategy):\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedCustom\"\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        return fl.common.ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "\n",
    "        # TODO WIP - add implementation\n",
    "\n",
    "        return []\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "\n",
    "        # TODO WIP - add implementation\n",
    "\n",
    "        return None, {}\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "\n",
    "        # TODO WIP - add implementation\n",
    "\n",
    "        return []\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        # TODO WIP - add implementation\n",
    "\n",
    "        return None, {}\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "\n",
    "        # TODO WIP - add implementation\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e427f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    strategy=FedCustom(),  # <-- pass the new strategy here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4562e",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import Code, EvaluateIns, EvaluateRes, FitIns, FitRes, GetParametersIns, GetParametersRes, Status\n",
    "from flwr.common import ndarrays_to_parameters, parameters_to_ndarrays\n",
    "\n",
    "\n",
    "class FlowerClient(fl.client.Client):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "\n",
    "        # Get parameters as a list of NumPy ndarray's\n",
    "        ndarrays: List[np.ndarray] = get_parameters(self.net)\n",
    "\n",
    "        # Serialize ndarray's into a Parameters object\n",
    "        parameters = ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return GetParametersRes(\n",
    "            status=status,\n",
    "            parameters=parameters,\n",
    "        )\n",
    "\n",
    "    def fit(self, ins: FitIns) -> FitRes:\n",
    "        print(f\"[Client {self.cid}] fit, config: {ins.config}\")\n",
    "\n",
    "        # Deserialize parameters to NumPy ndarray's\n",
    "        parameters_original = ins.parameters\n",
    "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
    "\n",
    "        # Update local model, train, get updated parameters\n",
    "        set_parameters(self.net, ndarrays_original)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        ndarrays_updated = get_parameters(self.net)\n",
    "\n",
    "        # Serialize ndarray's into a Parameters object\n",
    "        parameters_updated = ndarrays_to_parameters(ndarrays_updated)\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return FitRes(\n",
    "            status=status,\n",
    "            parameters=parameters_updated,\n",
    "            num_examples=len(self.trainloader),\n",
    "            metrics={},\n",
    "        )\n",
    "\n",
    "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "\n",
    "        # Deserialize parameters to NumPy ndarray's\n",
    "        parameters_original = ins.parameters\n",
    "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
    "\n",
    "        set_parameters(self.net, ndarrays_original)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        # return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return EvaluateRes(\n",
    "            status=status,\n",
    "            loss=float(loss),\n",
    "            num_examples=len(self.valloader),\n",
    "            metrics={\"accuracy\": float(accuracy)},\n",
    "        )\n",
    "\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0cadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerNumPyClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def numpyclient_fn(cid) -> FlowerNumPyClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerNumPyClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa44a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl.simulation.start_simulation(\n",
    "    client_fn=numpyclient_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c19e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
